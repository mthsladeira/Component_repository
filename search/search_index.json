{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"COMP4DRONES components repository Welcome to the COMP4DRONES component repository. To know more about COMP4DRONES please visit comp4drones.eu . This repository aims at providing common components usable in different application domains, in particular those covered by project use-cases. The requirements for using a components will be listed, as well as a documentation on how to use it. The component itself will be hosted by the partner who provides it.","title":"Home"},{"location":"#comp4drones-components-repository","text":"Welcome to the COMP4DRONES component repository. To know more about COMP4DRONES please visit comp4drones.eu . This repository aims at providing common components usable in different application domains, in particular those covered by project use-cases. The requirements for using a components will be listed, as well as a documentation on how to use it. The component itself will be hosted by the partner who provides it.","title":"COMP4DRONES components repository"},{"location":"about/","text":"COMP4DRONES is an ECSEL JU project coordinated by Indra that brings together a consortium of 49 partners with the aim of providing a framework of key enabling technologies for safe and autonomous drones. It brings to bear a holistically designed ecosystem from application to electronic components, realized as a tightly integrated multi-vendor and compositional UAV embedded architecture solution and a tool chain complementing the compositional architecture principles. The project will mainly focus on the following objectives: Ease the integration and customization of embedded drone systems. Enable drones to take safe autonomous decisions . Ensure the deployment of trusted communications . Minimize the design and verification effort for complex drone applications. Ensuring sustainable impact and creation of an industry-driven community. Demonstration and validation activities are essential to ensure the quality and relevance of innovations. COMP4DRONES will ease the development of new application and functionalities on the fields of transport, construction, surveillance and inspection, logistics, and agriculture How this website is build ? This website uses MKDocs with the tags plugin.","title":"About"},{"location":"about/#how-this-website-is-build","text":"This website uses MKDocs with the tags plugin.","title":"How this website is build ?"},{"location":"components/CEA_2/","text":"WP3-32_2 Reference Architecture Modelling and Code Generation The current embedded architectures of drones are organized in loosely coupled monolithic boards. Each board composed of processor, memory and communication resources (e.g. flight control, planning boards). This separation ensures that the subsystems operate almost independently from each other and avoids interference coming from the other parts. However, this approach does not support the continuous development of drone applications such as the ever-increasing demand on autonomy. The COMP4DRONES project will face this challenge by developing a compositional and integrated drone embedded reference architecture following the IMA principles, adapted to, and still considering, the drone resource constraints. With the support of WP6 tools, CEA will enable: The modelling of the compositional and integrated drone embedded reference architecture. The generation of well-formed and semantically-correct ROS code from this architecture.","title":"CEA - Reference Architecture Modelling and Code Generation"},{"location":"components/CEA_2/#reference-architecture-modelling-and-code-generation","text":"The current embedded architectures of drones are organized in loosely coupled monolithic boards. Each board composed of processor, memory and communication resources (e.g. flight control, planning boards). This separation ensures that the subsystems operate almost independently from each other and avoids interference coming from the other parts. However, this approach does not support the continuous development of drone applications such as the ever-increasing demand on autonomy. The COMP4DRONES project will face this challenge by developing a compositional and integrated drone embedded reference architecture following the IMA principles, adapted to, and still considering, the drone resource constraints. With the support of WP6 tools, CEA will enable: The modelling of the compositional and integrated drone embedded reference architecture. The generation of well-formed and semantically-correct ROS code from this architecture.","title":"Reference Architecture Modelling and Code Generation"},{"location":"components/example/","text":"BigFlop: a compute module for computing intensive tasks ID: WP3-XX Contributor: your company Owner: Licence: GPLv3 expected TRL: 6 KET: Contact: john@doe.com Description What is your component ? Explain clearly what is it and its purpose. The BigFlop ( just a random name ) is a small compute platform that performs computing intensive tasks. It can be embedded in a drone thanks to its small weight of only 31g, and its small form factor of 80x50x5 millimeters, and has multiple communication ports : UART, I2C, USB, and a standard camera serial interface CSI-2. The OrangeCrab, an open source FPGA board, just to add an image An SDK is provided to program the BigFlop with your own software. The SDK include librarie for common tasks: serialization with protobuf image processing with OpenCCV an other amazing stuff Current state What is the current state of this component? A prototype development version of the BigFlop is currently beeing produced, and the SDK is started. Improvements What improvements will you bring during the time of the C4D project? The electronics design will be validated, and a new, more compact version of the BigFlop will be designed and produced in small series. The SDK should reach V1.0. The product should be usable, and will be distributed to beta testers. Based on the return of experience of the beta testers, the finale product will be commercialized by June 2021.","title":"EXAMPLE"},{"location":"components/example/#bigflop-a-compute-module-for-computing-intensive-tasks","text":"ID: WP3-XX Contributor: your company Owner: Licence: GPLv3 expected TRL: 6 KET: Contact: john@doe.com","title":"BigFlop: a compute module for computing intensive tasks"},{"location":"components/example/#description","text":"What is your component ? Explain clearly what is it and its purpose. The BigFlop ( just a random name ) is a small compute platform that performs computing intensive tasks. It can be embedded in a drone thanks to its small weight of only 31g, and its small form factor of 80x50x5 millimeters, and has multiple communication ports : UART, I2C, USB, and a standard camera serial interface CSI-2. The OrangeCrab, an open source FPGA board, just to add an image An SDK is provided to program the BigFlop with your own software. The SDK include librarie for common tasks: serialization with protobuf image processing with OpenCCV an other amazing stuff","title":"Description"},{"location":"components/example/#current-state","text":"What is the current state of this component? A prototype development version of the BigFlop is currently beeing produced, and the SDK is started.","title":"Current state"},{"location":"components/example/#improvements","text":"What improvements will you bring during the time of the C4D project? The electronics design will be validated, and a new, more compact version of the BigFlop will be designed and produced in small series. The SDK should reach V1.0. The product should be usable, and will be distributed to beta testers. Based on the return of experience of the beta testers, the finale product will be commercialized by June 2021.","title":"Improvements"},{"location":"components/Socs_and_FPGAs/EDI_SoC/","text":"Modular SoC-based embedded reference architecture The currently available embedded drone flight controllers and computational platforms are based on a sequential processing paradigm, which is a limitation to the drone's onboard computational capacity. Modern heterogeneous systems that incorporate different computational paradigms (MPU, FPGA, GPU) promise advantages of great computational capabilities and even better power efficiency with a drawback of greater system complexity. In the COMP4DRONES project, we will utilize our experience in heterogeneous SoC systems to develop an SoC-based embedded reference architecture, which would be the core of the autonomous flight controller. This reference architecture will include a methodology on the algorithm separation between concurrent (digital logic) and sequential processing paradigms, a framework for managing and reusing different software components of the application and component intercommunication framework, including zero data copy communication. Main characteristics: Management of software and hardware components. Distribution of algorithms across heterogeneous processing paradigms. Novel approaches to sensing and processing pipelines. Usage in practice: Access to the developed software / hardware stacks. Access to the documentation and methodologies. Integration of different software and hardware components onto EDI indoor drone.","title":"EDI SoC"},{"location":"components/Socs_and_FPGAs/EDI_SoC/#modular-soc-based-embedded-reference-architecture","text":"The currently available embedded drone flight controllers and computational platforms are based on a sequential processing paradigm, which is a limitation to the drone's onboard computational capacity. Modern heterogeneous systems that incorporate different computational paradigms (MPU, FPGA, GPU) promise advantages of great computational capabilities and even better power efficiency with a drawback of greater system complexity. In the COMP4DRONES project, we will utilize our experience in heterogeneous SoC systems to develop an SoC-based embedded reference architecture, which would be the core of the autonomous flight controller. This reference architecture will include a methodology on the algorithm separation between concurrent (digital logic) and sequential processing paradigms, a framework for managing and reusing different software components of the application and component intercommunication framework, including zero data copy communication. Main characteristics: Management of software and hardware components. Distribution of algorithms across heterogeneous processing paradigms. Novel approaches to sensing and processing pipelines. Usage in practice: Access to the developed software / hardware stacks. Access to the documentation and methodologies. Integration of different software and hardware components onto EDI indoor drone.","title":"Modular\u00a0SoC-based\u00a0embedded reference architecture"},{"location":"components/Socs_and_FPGAs/TUE/","text":"WP3-08_1 and WP3-08_2 A compact, lightweight platform (MPSOC FPGA-based, incl. RTOS) hardware Providing a composable and predictable Multi Processor System On Chip (MPSOC) implemented on FPGA. Providing a real-time micro kernel to manage virtualization and resource management in mixed criticality systems. Providing the development and analysis toolchain for implementing real-time systems software on MPSOC. Very accurate real-time interface/library for integration with above platform, Linux, and/or ROS Providing a predictable software framework based on ROS2 for developing real-time software for robotic systems. Modeling and analysis of the real-time behaviour of the robotic systems Proving a real-time messaging framework for robot to robot communication based on Data Distribution Service (DDS) protocol.","title":"TUE - A compact, lightweight platform (MPSOC FPGA-based, incl. RTOS)"},{"location":"components/Socs_and_FPGAs/TUE/#a-compact-lightweight-platform-mpsoc-fpga-based-incl-rtos","text":"","title":"A compact, lightweight platform (MPSOC FPGA-based, incl. RTOS)"},{"location":"components/Socs_and_FPGAs/TUE/#hardware","text":"Providing a composable and predictable Multi Processor System On Chip (MPSOC) implemented on FPGA. Providing a real-time micro kernel to manage virtualization and resource management in mixed criticality systems. Providing the development and analysis toolchain for implementing real-time systems software on MPSOC.","title":"hardware"},{"location":"components/Socs_and_FPGAs/TUE/#very-accurate-real-time-interfacelibrary-for-integration-with-above-platform-linux-andor-ros","text":"Providing a predictable software framework based on ROS2 for developing real-time software for robotic systems. Modeling and analysis of the real-time behaviour of the robotic systems Proving a real-time messaging framework for robot to robot communication based on Data Distribution Service (DDS) protocol.","title":"Very accurate real-time interface/library for integration with above platform, Linux, and/or ROS"},{"location":"components/Socs_and_FPGAs/UNIMORE/","text":"Onboard Compute Platform Desing Methodolgy Definition of Onboard Compute Platforms (based on commercial off-the-shelf, heterogeneous FPGA SoCs) and methodologies for the deployment of specialized cluster-based, accelerator architecture templates. Compute Platform design should enable easily accessible acceleration for computationally intensive algorithms for Flight Navigation, Positioning, Coordination and Communication. Improvements compare state-of-the-art Onboard Compute Platform are expected in terms of more computational power present on board; a wider set of services and complex algorithms runnable on board; an easy to use deployment methodology for the definition of application-specific accelerated services.","title":"UNIMORE - Onboard Compute Platform Desing Methodolgy"},{"location":"components/Socs_and_FPGAs/UNIMORE/#onboard-compute-platform-desing-methodolgy","text":"Definition of Onboard Compute Platforms (based on commercial off-the-shelf, heterogeneous FPGA SoCs) and methodologies for the deployment of specialized cluster-based, accelerator architecture templates. Compute Platform design should enable easily accessible acceleration for computationally intensive algorithms for Flight Navigation, Positioning, Coordination and Communication. Improvements compare state-of-the-art Onboard Compute Platform are expected in terms of more computational power present on board; a wider set of services and complex algorithms runnable on board; an easy to use deployment methodology for the definition of application-specific accelerated services.","title":"Onboard Compute Platform Desing Methodolgy"},{"location":"components/Socs_and_FPGAs/UNISS/","text":"Onboard Compute Platform Design Paradigm ID: WP3-28 Contributor: UNISS Owner: University of Sassari Licence: expected TRL: 4 KET: 2.4.1 - Data Fusion & Processing Contact: (fpalumbo, tfanni)@uniss.it Requirements UC5-FNC-005 : The system SHALL enable advanced on board computation by means of dedicated and optimized accelerators. UC5-FNC-005 : The accelerator shall be built in an energy-and performance-aware manner and, where possible, should support different erformance trade-off and/or functionalities. Specification Onboard computing platforms implementing different working points (i.e. trade-offs among Quality of Service and Energy consumption) or functionalities (i.e. different convolutional kernels). Improvements Extended computational power by leveraging on heterogeneous co-processing units that shall enable advanced and flexible on board computation. Connection with WP4 will lead to integrate this adaptive acceleratores into a more advanced computing infrastructure by integrating it with WP3-22.","title":"UNISS - Onboard Compute Platform Design Paradigm"},{"location":"components/Socs_and_FPGAs/UNISS/#onboard-compute-platform-design-paradigm","text":"ID: WP3-28 Contributor: UNISS Owner: University of Sassari Licence: expected TRL: 4 KET: 2.4.1 - Data Fusion & Processing Contact: (fpalumbo, tfanni)@uniss.it","title":"Onboard Compute Platform Design Paradigm"},{"location":"components/Socs_and_FPGAs/UNISS/#requirements","text":"UC5-FNC-005 : The system SHALL enable advanced on board computation by means of dedicated and optimized accelerators. UC5-FNC-005 : The accelerator shall be built in an energy-and performance-aware manner and, where possible, should support different erformance trade-off and/or functionalities.","title":"Requirements"},{"location":"components/Socs_and_FPGAs/UNISS/#specification","text":"Onboard computing platforms implementing different working points (i.e. trade-offs among Quality of Service and Energy consumption) or functionalities (i.e. different convolutional kernels).","title":"Specification"},{"location":"components/Socs_and_FPGAs/UNISS/#improvements","text":"Extended computational power by leveraging on heterogeneous co-processing units that shall enable advanced and flexible on board computation. Connection with WP4 will lead to integrate this adaptive acceleratores into a more advanced computing infrastructure by integrating it with WP3-22.","title":"Improvements"},{"location":"components/Socs_and_FPGAs/UNIVAQ/","text":"Efficient digital implementation of controllers Efficient digital implementation of controllers, designed on the basis of a discrete\u2013time models, on FPGAs. In order to operate safely, the controller shall enable the functionality of compensating and rejecting environmental perturbations, measurement uncertainties, and possible faults. Increased performance of the controller, with reduced response time. Robustness of the controller with respect to environmental disturbances and increased resiliency.","title":"UNIVAQ - Efficient digital implementation of controllers"},{"location":"components/Socs_and_FPGAs/UNIVAQ/#efficient-digital-implementation-of-controllers","text":"Efficient digital implementation of controllers, designed on the basis of a discrete\u2013time models, on FPGAs. In order to operate safely, the controller shall enable the functionality of compensating and rejecting environmental perturbations, measurement uncertainties, and possible faults. Increased performance of the controller, with reduced response time. Robustness of the controller with respect to environmental disturbances and increased resiliency.","title":"Efficient digital implementation of controllers"},{"location":"components/complete%20UAS/ENAC_paparazzi/","text":"Paparazzi UAV ID: WP3-13 Contributor: ENAC Owner: Licence: GPL expected TRL: 5 KET: Intelligent mission management, Intelligent outer loop control, Take-off, Landing, Planning and scheduling, Fail-safe mission Contact: fabien.bonneval@enac.fr Description Paparazzi is a complete system of open source hardware and software for Unmanned Aircraft Systems (UAS), including both the airborne autopilot as well as complete ground station mission planning and monitoring software utilizing a bi-directional datalink for telemetry and control. Paparazzi has been created at ENAC in 2003, and is now supported by other institutes such as MAVLAB of the TU-Delft, individual developers, and some private UAV companies from several countries. The Paparazzi system was initially designed for robust small fixed-wing aircrafts in 2003, but it now support several other configurations and concepts such as high-aspect ratio gliders, multi-rotors, transitioning vehicles, and rovers. Today, Paparazzi flies on 16cm Quark up to 4.3 meter spanned Adler UAV from University of Stuttgart. The popular UAV platform Bebop2 from Parrot2 can also be used to run the Paparazzi software. See the Wiki and the Github repository . Current state Paparazzi is a running, working project, but it lacks some tools to make it more stable. Improvements The methods coming from the WP6 will be applied to the paparazzi architecture and its modules. Standards and use case from WP2 and WP1 will also be taken into account. Overview Figure 1 The global view of the system (see figure 1) is very typical of UAV systems: Ground segment: all the ground software and hardware infrastructures that are used to prepare, monitor and analyze the flight. Airborne segment: the aircraft, its hardware parts including payload and all the embedded software to control the flight (from stabilization to decision making). Communication segment: defines all the communication links and protocols between the ground and airborne segments. Safety link: safety remote control that can be separated from the ground station for short range direct control. System architecture Figure 2 The Paparazzi system architecture is show in Figure 3. The UAV (in blue) is navigating autonomously and is monitored and controlled from the ground (in brown). The ground control station (GCS), or GCS agent, provides a graphical user interface with telemetry data received by the link agent which manages the ground-based radio modem. The link agent distributes telemetry data across the network (a single computer, a local network or the internet) where it can be used locally or remotely by the: (1) server - an agent that logs, distributes, and preprocesses these messages for the GCS and other agents; (2) messages - a real-time numeric display of all telemetry data; (3) a number of other useful agents. These agents are: a GCS-based flight plan editor to modify waypoints a UAV simulator to test flight plans and code modifications a real-time plotter for graphical telemetry data visualization a log plotter for graphical telemetry visualization after a flight All of these processes run simultaneously and each module is independently launched and can be configured via the Paparazzi Center. Communication with the autopilot is based on a custom protocol and message definition, called Pprzlink. Libraries exist for airborne and ground segments, in multiple languages (C, OCaml, Python), and for multiple transport protocols (Serial, UDP, Ivy). On the ground segment, ground control station uses Pprzlink with the Ivy transport. Ivy is a software publish/subscribe bus based on UDP or TCP to exchange text messages. There are four ways to extend Paparazzi functionalities: Using Pprzlink with the current ground station tools Using Pprzlink independently of the ground station tools Adding a dedicated board on the drone and using Pprzlink to communicate directly with the autopilot (usually with the serial transport) Adding a module to the autopilot itself A combination of these options can be used at the same time to achieve specific goals. Using Pprzlink with the ground station The easier way to interact with Paparazzi is to create a new agent as part of the ground station. All parameters and configuration files are easily accessible, making it easy to interact with the drone or display new data on the GCS. As example, the Interactive Informatics team of ENAC used it to design novel human-drone interactions for safety pilots and adaptable interactions for pilots with disabilities. Using Pprzlink without the ground station It is also possible to use Pprzlink on the ground by interacting directly with the datalink. This approach gives less high-level services but makes it simpler to exchange custom messages. Adding a dedicated board on the drone Custom dedicated boards (Raspberry or Arduino for instance) can be integrated in the drone and interact with the autopilot through a local link, typically a serial interface between the dedicated board and the autopilot. The type of interaction is the same than with a ground agent. Adding a module to the autopilot itself The modularity of the airborne architecture (see Figure 3) also enables users to write custom modules that will run on the autopilot itself. All sensors data, payload or actuators are then available to this module. Modules are the building blocks of the airborne architecture. These modules can do various things such as handling a specific sensor connected to the autopilot, enhance navigation capabilities, implement custom stabilization or guidance control loops... Figure 3 Paparazzi also has a simulator based on JSBSim . The autopilot can be built for both the hardware target and the simulator target. The simulator then uses the same code that will run on the real hardware. Custom modules that use platform specific capabilities must provide alternative code in order to be built for another target, such as the simulator.","title":"Paparazzi"},{"location":"components/complete%20UAS/ENAC_paparazzi/#paparazzi-uav","text":"ID: WP3-13 Contributor: ENAC Owner: Licence: GPL expected TRL: 5 KET: Intelligent mission management, Intelligent outer loop control, Take-off, Landing, Planning and scheduling, Fail-safe mission Contact: fabien.bonneval@enac.fr","title":"Paparazzi UAV"},{"location":"components/complete%20UAS/ENAC_paparazzi/#description","text":"Paparazzi is a complete system of open source hardware and software for Unmanned Aircraft Systems (UAS), including both the airborne autopilot as well as complete ground station mission planning and monitoring software utilizing a bi-directional datalink for telemetry and control. Paparazzi has been created at ENAC in 2003, and is now supported by other institutes such as MAVLAB of the TU-Delft, individual developers, and some private UAV companies from several countries. The Paparazzi system was initially designed for robust small fixed-wing aircrafts in 2003, but it now support several other configurations and concepts such as high-aspect ratio gliders, multi-rotors, transitioning vehicles, and rovers. Today, Paparazzi flies on 16cm Quark up to 4.3 meter spanned Adler UAV from University of Stuttgart. The popular UAV platform Bebop2 from Parrot2 can also be used to run the Paparazzi software. See the Wiki and the Github repository .","title":"Description"},{"location":"components/complete%20UAS/ENAC_paparazzi/#current-state","text":"Paparazzi is a running, working project, but it lacks some tools to make it more stable.","title":"Current state"},{"location":"components/complete%20UAS/ENAC_paparazzi/#improvements","text":"The methods coming from the WP6 will be applied to the paparazzi architecture and its modules. Standards and use case from WP2 and WP1 will also be taken into account.","title":"Improvements"},{"location":"components/complete%20UAS/ENAC_paparazzi/#overview","text":"Figure 1 The global view of the system (see figure 1) is very typical of UAV systems: Ground segment: all the ground software and hardware infrastructures that are used to prepare, monitor and analyze the flight. Airborne segment: the aircraft, its hardware parts including payload and all the embedded software to control the flight (from stabilization to decision making). Communication segment: defines all the communication links and protocols between the ground and airborne segments. Safety link: safety remote control that can be separated from the ground station for short range direct control.","title":"Overview"},{"location":"components/complete%20UAS/ENAC_paparazzi/#system-architecture","text":"Figure 2 The Paparazzi system architecture is show in Figure 3. The UAV (in blue) is navigating autonomously and is monitored and controlled from the ground (in brown). The ground control station (GCS), or GCS agent, provides a graphical user interface with telemetry data received by the link agent which manages the ground-based radio modem. The link agent distributes telemetry data across the network (a single computer, a local network or the internet) where it can be used locally or remotely by the: (1) server - an agent that logs, distributes, and preprocesses these messages for the GCS and other agents; (2) messages - a real-time numeric display of all telemetry data; (3) a number of other useful agents. These agents are: a GCS-based flight plan editor to modify waypoints a UAV simulator to test flight plans and code modifications a real-time plotter for graphical telemetry data visualization a log plotter for graphical telemetry visualization after a flight All of these processes run simultaneously and each module is independently launched and can be configured via the Paparazzi Center. Communication with the autopilot is based on a custom protocol and message definition, called Pprzlink. Libraries exist for airborne and ground segments, in multiple languages (C, OCaml, Python), and for multiple transport protocols (Serial, UDP, Ivy). On the ground segment, ground control station uses Pprzlink with the Ivy transport. Ivy is a software publish/subscribe bus based on UDP or TCP to exchange text messages. There are four ways to extend Paparazzi functionalities: Using Pprzlink with the current ground station tools Using Pprzlink independently of the ground station tools Adding a dedicated board on the drone and using Pprzlink to communicate directly with the autopilot (usually with the serial transport) Adding a module to the autopilot itself A combination of these options can be used at the same time to achieve specific goals.","title":"System architecture"},{"location":"components/complete%20UAS/ENAC_paparazzi/#using-pprzlink-with-the-ground-station","text":"The easier way to interact with Paparazzi is to create a new agent as part of the ground station. All parameters and configuration files are easily accessible, making it easy to interact with the drone or display new data on the GCS. As example, the Interactive Informatics team of ENAC used it to design novel human-drone interactions for safety pilots and adaptable interactions for pilots with disabilities.","title":"Using Pprzlink with the ground station"},{"location":"components/complete%20UAS/ENAC_paparazzi/#using-pprzlink-without-the-ground-station","text":"It is also possible to use Pprzlink on the ground by interacting directly with the datalink. This approach gives less high-level services but makes it simpler to exchange custom messages.","title":"Using Pprzlink without the ground station"},{"location":"components/complete%20UAS/ENAC_paparazzi/#adding-a-dedicated-board-on-the-drone","text":"Custom dedicated boards (Raspberry or Arduino for instance) can be integrated in the drone and interact with the autopilot through a local link, typically a serial interface between the dedicated board and the autopilot. The type of interaction is the same than with a ground agent.","title":"Adding a dedicated board on the drone"},{"location":"components/complete%20UAS/ENAC_paparazzi/#adding-a-module-to-the-autopilot-itself","text":"The modularity of the airborne architecture (see Figure 3) also enables users to write custom modules that will run on the autopilot itself. All sensors data, payload or actuators are then available to this module. Modules are the building blocks of the airborne architecture. These modules can do various things such as handling a specific sensor connected to the autopilot, enhance navigation capabilities, implement custom stabilization or guidance control loops... Figure 3 Paparazzi also has a simulator based on JSBSim . The autopilot can be built for both the hardware target and the simulator target. The simulator then uses the same code that will run on the real hardware. Custom modules that use platform specific capabilities must provide alternative code in order to be built for another target, such as the simulator.","title":"Adding a module to the autopilot itself"},{"location":"components/complete%20UAS/SCALIAN/","text":"EZ_Chains SOA* Architecture","title":"SCALIAN \u2013 EZ_Chains SOA* Architecture"},{"location":"components/complete%20UAS/SCALIAN/#ez_chains-soa-architecture","text":"","title":"EZ_Chains SOA* Architecture"},{"location":"components/computer_vision_and_image_processing/BUT/","text":"Sensor information algorithms In this component BUT will implement/improve sensor data processing algorithms which will include software and firmware for FPGA. This will involve video processing algorithms (for example HDR algorithms). HDR multi-exposure fusion algorithm to be implemented in the drone, possibly implementing also tone mapping and/or ghost removal (with most probably somewhat liited capabilities) in order to \"feed\" further image and video processing subsystems in the drone by image information with high dynamic range. As a \"demonstrator\", we can also provide e.g. object detection in HDR. Increased performance of the algoritms, which will reduce latency and increase throughput. Robustness of the controller with respect to environmental disturbances and increased resiliency. This improvement will be based on increased robustness of the video processing with respect to HDR while keeping the processing means and extent of video processing \"unchanged\" thanks to the tone mapping that virtually brings the \"same image format\" as in usual processing.","title":"BUT algorithms"},{"location":"components/computer_vision_and_image_processing/BUT/#sensor-information-algorithms","text":"In this component BUT will implement/improve sensor data processing algorithms which will include software and firmware for FPGA. This will involve video processing algorithms (for example HDR algorithms). HDR multi-exposure fusion algorithm to be implemented in the drone, possibly implementing also tone mapping and/or ghost removal (with most probably somewhat liited capabilities) in order to \"feed\" further image and video processing subsystems in the drone by image information with high dynamic range. As a \"demonstrator\", we can also provide e.g. object detection in HDR. Increased performance of the algoritms, which will reduce latency and increase throughput. Robustness of the controller with respect to environmental disturbances and increased resiliency. This improvement will be based on increased robustness of the video processing with respect to HDR while keeping the processing means and extent of video processing \"unchanged\" thanks to the tone mapping that virtually brings the \"same image format\" as in usual processing.","title":"Sensor information algorithms"},{"location":"components/computer_vision_and_image_processing/HIB/","text":"Computer Vision Components for drones AI system built upon deep learning techniques in order to improve the way of interpreting surroundings and detecting scenarios from data captured with drones AI system built upon automatic algorithms for the autodetection/geo-referencing of road elements and taking cloud of points generated by a LIDAR sensor. Accelerate the Constructive Process of a Civil Infrastructure.","title":"HIB - Computer Vision Components for drones"},{"location":"components/computer_vision_and_image_processing/HIB/#computer-vision-components-for-drones","text":"AI system built upon deep learning techniques in order to improve the way of interpreting surroundings and detecting scenarios from data captured with drones AI system built upon automatic algorithms for the autodetection/geo-referencing of road elements and taking cloud of points generated by a LIDAR sensor. Accelerate the Constructive Process of a Civil Infrastructure.","title":"Computer Vision Components for drones"},{"location":"components/computer_vision_and_image_processing/IMEC_1/","text":"Hyperspectral payload Hyperspectral cameras can improve detection of material imperfections. The hyperspectral payload will be based on imec\u2019s uav platform: (dual)mosaic sensors/cameras with Ximea break out board and Jetson TX2 board. Regarding the software blocks, we will reuse Airobot\u2019s server based interface for ground controller with imec\u2019s camera commands. The hardware hyperspectral payload is able to communicate with the AiroCore platform. Making a rugged box: hyperspectral measurements for detecting and quantifying corrosion damage on offshore structures in realistic conditions (wind up to 5 Beaufort, wave heights of 1,2-1,5m, minimum temperature of -10\u00b0C).","title":"IMEC - Hyperspectral payload"},{"location":"components/computer_vision_and_image_processing/IMEC_1/#hyperspectral-payload","text":"Hyperspectral cameras can improve detection of material imperfections. The hyperspectral payload will be based on imec\u2019s uav platform: (dual)mosaic sensors/cameras with Ximea break out board and Jetson TX2 board. Regarding the software blocks, we will reuse Airobot\u2019s server based interface for ground controller with imec\u2019s camera commands. The hardware hyperspectral payload is able to communicate with the AiroCore platform. Making a rugged box: hyperspectral measurements for detecting and quantifying corrosion damage on offshore structures in realistic conditions (wind up to 5 Beaufort, wave heights of 1,2-1,5m, minimum temperature of -10\u00b0C).","title":"Hyperspectral payload"},{"location":"components/computer_vision_and_image_processing/IMEC_2/","text":"Hyperspectral image processing The goal is to use hyperspectral camera data for future navigation : localization and detection. imec will reuse the hyperspectral processing software pipeline as a start base and rely on the in-house built Quasar programming framework to efficiently implement algorithms on the Nvidia Jetson boards. The integration of algorithms to restore hyperspectral images by removing image degradations caused by vibrations, wavelength dependent fading and spectral changes due to lighting conditions. Automatic hyperspectral image based detection and quantification of corrosion using AI technology with an accuracy of 80% compared to human inspections.","title":"IMEC - Hyperspectral image processing"},{"location":"components/computer_vision_and_image_processing/IMEC_2/#hyperspectral-image-processing","text":"The goal is to use hyperspectral camera data for future navigation : localization and detection. imec will reuse the hyperspectral processing software pipeline as a start base and rely on the in-house built Quasar programming framework to efficiently implement algorithms on the Nvidia Jetson boards. The integration of algorithms to restore hyperspectral images by removing image degradations caused by vibrations, wavelength dependent fading and spectral changes due to lighting conditions. Automatic hyperspectral image based detection and quantification of corrosion using AI technology with an accuracy of 80% compared to human inspections.","title":"Hyperspectral image processing"},{"location":"components/computer_vision_and_image_processing/INDRA_1/","text":"Visible and Infrared HD camera The camera comes in 3 flavors: a visible spectrum camera, an infrared one, and a dual camera including both visible and infrared spectrum. All cameras are gyro-stabilized on 3 axis. Definitions: Visible: 750x580 Infrared: 640x480 GCS - HMI Human - Machine Interface of the Ground Control Station related to the HD video payload. Analysis, design, development and tests that enable communication between the frontend and the backend of the control station application so that the actions requested by the user, are sent to the autopilot.","title":"INDRA - Payload (Single Visible HD)"},{"location":"components/computer_vision_and_image_processing/INDRA_1/#visible-and-infrared-hd-camera","text":"The camera comes in 3 flavors: a visible spectrum camera, an infrared one, and a dual camera including both visible and infrared spectrum. All cameras are gyro-stabilized on 3 axis. Definitions: Visible: 750x580 Infrared: 640x480","title":"Visible and Infrared HD camera"},{"location":"components/computer_vision_and_image_processing/INDRA_1/#gcs-hmi","text":"Human - Machine Interface of the Ground Control Station related to the HD video payload. Analysis, design, development and tests that enable communication between the frontend and the backend of the control station application so that the actions requested by the user, are sent to the autopilot.","title":"GCS - HMI"},{"location":"components/misc/ENSMA_1/","text":"WP3-14_1 Control components that implement potential barriers A control loop that implements a \"potential field\" that prevents the drone to access certain areas by evaluating its position, geofences and potential obstacles in the environment","title":"ENSMA - Control components that implement potential barriers"},{"location":"components/misc/ENSMA_1/#control-components-that-implement-potential-barriers","text":"A control loop that implements a \"potential field\" that prevents the drone to access certain areas by evaluating its position, geofences and potential obstacles in the environment","title":"Control components that implement potential barriers"},{"location":"components/misc/ENSMA_2/","text":"WP3-14_2 Multi-agent swarm control A multi-agent control system to manage multiple drones in a swarm","title":"ENSMA - Multi-agent swarm control"},{"location":"components/misc/ENSMA_2/#multi-agent-swarm-control","text":"A multi-agent control system to manage multiple drones in a swarm","title":"Multi-agent swarm control"},{"location":"components/misc/IKERLAN/","text":"WP3-01 Safety function - Pre-Certified SOM Analysis of current Safety Standards will be done, and appropriate Safety Concept will be conducted on the development of the HW/SW elements necessary to execute the Safety Function. The Safety function will integrate several sensors to detect obstacles and avoid causing harm to goods or people. As an end point a HW/SW module that implements the Safety Function will be developed. Emergent MPSoC technologies will be used to have powerful computation capabilities. Lidar/radar D&A => update next week","title":"IKERLAN - Safety function - Pre-Certified SOM"},{"location":"components/misc/IKERLAN/#safety-function-pre-certified-som","text":"Analysis of current Safety Standards will be done, and appropriate Safety Concept will be conducted on the development of the HW/SW elements necessary to execute the Safety Function. The Safety function will integrate several sensors to detect obstacles and avoid causing harm to goods or people. As an end point a HW/SW module that implements the Safety Function will be developed. Emergent MPSoC technologies will be used to have powerful computation capabilities. Lidar/radar D&A => update next week","title":"Safety function - Pre-Certified SOM"},{"location":"components/misc/UDANET_1/","text":"WP3-36_1 Smart and predictive energy management system Objective An energy management system is vital to optimize the energy life and the purpose of the system: it will continuously monitor important system parameters, while dealing with the varying power demands of the many aspects, the objectives of the mission and optimizing the usage of the energy. The designed predictive energy management system will be verified and tested via Software in The Loop. Individual technical contribution We seeks to find control inputs and vehicle trajectory between initial and final configurations that minimize the consumed energy during a specific mission. Energetic Model Formulation: drone dynamic model, actuators and battery (or energy souce) dynamic. Optimal energy trajectory planning will be formulated as a minimization problem, by which the final consumed energy is used as the cost function. In addition the state variables and control variables in are constrained to satisfy the vehicle and battery dynamics, boundary conditions. Input The mission data: for example initial and final positions, time interval etc. Output Control inputs that rule the motion and vehicle trajectory to optimize energy consumption","title":"UDANET - Smart and predictive energy management system"},{"location":"components/misc/UDANET_1/#smart-and-predictive-energy-management-system","text":"","title":"Smart and predictive energy management system"},{"location":"components/misc/UDANET_1/#objective","text":"An energy management system is vital to optimize the energy life and the purpose of the system: it will continuously monitor important system parameters, while dealing with the varying power demands of the many aspects, the objectives of the mission and optimizing the usage of the energy. The designed predictive energy management system will be verified and tested via Software in The Loop.","title":"Objective"},{"location":"components/misc/UDANET_1/#individual-technical-contribution","text":"We seeks to find control inputs and vehicle trajectory between initial and final configurations that minimize the consumed energy during a specific mission. Energetic Model Formulation: drone dynamic model, actuators and battery (or energy souce) dynamic. Optimal energy trajectory planning will be formulated as a minimization problem, by which the final consumed energy is used as the cost function. In addition the state variables and control variables in are constrained to satisfy the vehicle and battery dynamics, boundary conditions.","title":"Individual technical contribution"},{"location":"components/misc/UDANET_1/#input","text":"The mission data: for example initial and final positions, time interval etc.","title":"Input"},{"location":"components/misc/UDANET_1/#output","text":"Control inputs that rule the motion and vehicle trajectory to optimize energy consumption","title":"Output"},{"location":"components/misc/UDANET_2/","text":"WP3-36_2 AI drone system modules Objective Design, training and testing AI algorithms with integrated infrared thermal and camera imaging system to detect and identify parasite animals, to classify leaf diseases. Individual technical contribution The design and implementation of AI methods to classify leaf diseases and detect parasitic animals Analysis and development of the training, verification and testing phases of the algorithms Input Camera data Dataset to train, validate and test the algorithms Output Plant health status classification","title":"UDANET - AI drone system modules"},{"location":"components/misc/UDANET_2/#ai-drone-system-modules","text":"","title":"AI drone system modules"},{"location":"components/misc/UDANET_2/#objective","text":"Design, training and testing AI algorithms with integrated infrared thermal and camera imaging system to detect and identify parasite animals, to classify leaf diseases.","title":"Objective"},{"location":"components/misc/UDANET_2/#individual-technical-contribution","text":"The design and implementation of AI methods to classify leaf diseases and detect parasitic animals Analysis and development of the training, verification and testing phases of the algorithms","title":"Individual technical contribution"},{"location":"components/misc/UDANET_2/#input","text":"Camera data Dataset to train, validate and test the algorithms","title":"Input"},{"location":"components/misc/UDANET_2/#output","text":"Plant health status classification","title":"Output"},{"location":"components/misc/UWB/","text":"WP3-26 Droneport: an autonomous drone battery management system Droneport (DP) is a complex system for autonomous drone battery management. It can either change battery packs or fast charge small drones. Droneport HW architecture Droneport consists of Drone landing place with landing markers or beacons Battery exchange unit / robotic manipulator Battery management unit for charging and storage Wireless communication to the drone/swarms Optional wired power connection to the drone on the Droneport Droneport SW architecture Droneport SW architecture consists of Drone to DP communication protocol Drone landing assistant Battery exchange system control Charge control Battery management software DP software provides open API for interoperability with various drones flight controllers. PX4 and Mavlink extensions for autonomous drone battery management MAVLink is a very lightweight messaging protocol with hybrid publish-subscribe communication with drones and between onboard drone components. (see https://mavlink.io/en/) PX4 is a complex flight control software widely used in drone community. It performs various basic flight controls and mission tasks. (see https://px4.io) The goal is to create MAVLink extensions via messages specialized for autonomous drone battery management (Drone Port). These extension modules will cover the communication messages prepared for MAVLink library auto generation process. The messages will be subsequently implemented to PX4.","title":"UWB - Autonomous drone battery management"},{"location":"components/misc/UWB/#droneport-an-autonomous-drone-battery-management-system","text":"Droneport (DP) is a complex system for autonomous drone battery management. It can either change battery packs or fast charge small drones.","title":"Droneport: an autonomous drone battery management system"},{"location":"components/misc/UWB/#droneport-hw-architecture","text":"Droneport consists of Drone landing place with landing markers or beacons Battery exchange unit / robotic manipulator Battery management unit for charging and storage Wireless communication to the drone/swarms Optional wired power connection to the drone on the Droneport","title":"Droneport HW architecture"},{"location":"components/misc/UWB/#droneport-sw-architecture","text":"Droneport SW architecture consists of Drone to DP communication protocol Drone landing assistant Battery exchange system control Charge control Battery management software DP software provides open API for interoperability with various drones flight controllers.","title":"Droneport SW architecture"},{"location":"components/misc/UWB/#px4-and-mavlink-extensions-for-autonomous-drone-battery-management","text":"MAVLink is a very lightweight messaging protocol with hybrid publish-subscribe communication with drones and between onboard drone components. (see https://mavlink.io/en/) PX4 is a complex flight control software widely used in drone community. It performs various basic flight controls and mission tasks. (see https://px4.io) The goal is to create MAVLink extensions via messages specialized for autonomous drone battery management (Drone Port). These extension modules will cover the communication messages prepared for MAVLink library auto generation process. The messages will be subsequently implemented to PX4.","title":"PX4 and Mavlink extensions for autonomous drone battery management"},{"location":"components/positioning/ACCORDE_1/","text":"WP3-15_1 UWB based indoor positioning Decawave based indoor positioning module IPS objectives directly related to IPS platform elements Cost-effective solution, Easy to deploy, Flexible, Versatile, Real-Time Solution: Custom design by ACORDE: UWB processing+storage+configuration capabilities Preliminary Evaluation Tests with evaluation board of the radio chipset ongoing","title":"ACCORDE - UWB based indoor positioning"},{"location":"components/positioning/ACCORDE_1/#uwb-based-indoor-positioning","text":"Decawave based indoor positioning module IPS objectives directly related to IPS platform elements Cost-effective solution, Easy to deploy, Flexible, Versatile, Real-Time Solution: Custom design by ACORDE: UWB processing+storage+configuration capabilities Preliminary Evaluation Tests with evaluation board of the radio chipset ongoing","title":"UWB based indoor positioning"},{"location":"components/positioning/ACCORDE_2/","text":"WP3-15_2 Multi-antenna GNSS/INS based navigation Georeferenced position and attitude system providing a trustable positioning and attitude based on the fusion of multi-antenna/multi-receiver data and of additional sensors like accelerometers, gyroscopes and barometer HW/SW upgrades applied with respect to the initial baseline system HW upgrades: GNSS COTs with security features SW upgrades: Updated BSP : extended support for updated HW platform License free RTOS port ready (Alpha version)","title":"ACCORDE - Multi-antenna GNSS/INS based navigation"},{"location":"components/positioning/ACCORDE_2/#multi-antenna-gnssins-based-navigation","text":"Georeferenced position and attitude system providing a trustable positioning and attitude based on the fusion of multi-antenna/multi-receiver data and of additional sensors like accelerometers, gyroscopes and barometer HW/SW upgrades applied with respect to the initial baseline system HW upgrades: GNSS COTs with security features SW upgrades: Updated BSP : extended support for updated HW platform License free RTOS port ready (Alpha version)","title":"Multi-antenna GNSS/INS based navigation"},{"location":"components/positioning/FADA-CATEC/","text":"WP3-30 Multi-sensor positioning Storage of the raw data from the LIDAR that provide the environment point cloud Detect obstacles by preventing flight to these obstacles Mapping of the surrounding environment Precision of the navigation in real time less than 1m Integration in ROS operating system, together with the DJI SDK (http://wiki.ros.org/dji_sdk) High level control in order to autonomously navigate in the indoor environment","title":"FADA-CATEC - Indoor positioning module"},{"location":"components/positioning/FADA-CATEC/#multi-sensor-positioning","text":"Storage of the raw data from the LIDAR that provide the environment point cloud Detect obstacles by preventing flight to these obstacles Mapping of the surrounding environment Precision of the navigation in real time less than 1m Integration in ROS operating system, together with the DJI SDK (http://wiki.ros.org/dji_sdk) High level control in order to autonomously navigate in the indoor environment","title":"Multi-sensor positioning"},{"location":"components/positioning/MODIS/","text":"WP3-20 Multi-sensor positioning Highly embedded customizable platform for SLAM technique, equipped with magnetometers, compasses, GPS (optional), a gyroscope, accelerometer. Additionally the board will be provided with a serial communication bus (or more than one), e.g. USART, SPI, MavLink and a 32-bit MCU. Orientation capabilities through geomagnetic field mapping with similar or higher accuracy to GPS when in GPS-loss navigation and improved precision when GPS is active Improved algorithms for real-time data analytics, and data compression.","title":"MODIS - multi-sensor positioning"},{"location":"components/positioning/MODIS/#multi-sensor-positioning","text":"Highly embedded customizable platform for SLAM technique, equipped with magnetometers, compasses, GPS (optional), a gyroscope, accelerometer. Additionally the board will be provided with a serial communication bus (or more than one), e.g. USART, SPI, MavLink and a 32-bit MCU. Orientation capabilities through geomagnetic field mapping with similar or higher accuracy to GPS when in GPS-loss navigation and improved precision when GPS is active Improved algorithms for real-time data analytics, and data compression.","title":"Multi-sensor positioning"},{"location":"components/secure_communications/CEA/","text":"WP3-32_1 TSN Queue Mapper On the drone, it is expected that communications between different components could be supported by a TSN Network (Time-Sensitive Network). TSN is a group of IEEE Standards that targets support of deterministic communications over standard Ethernet. Several traffic Queues can be defined to support different levels of TSN support (determinism, controlled latency, best efforts, etc.). This software is in charge of setting up the TSN queues and the routing rules so that Traffic with specific QoS requirements can be handled as expected in the TSN network (on-board). This software is required to setup the TSN flows.","title":"CEA - TSN Queue Mapper"},{"location":"components/secure_communications/CEA/#tsn-queue-mapper","text":"On the drone, it is expected that communications between different components could be supported by a TSN Network (Time-Sensitive Network). TSN is a group of IEEE Standards that targets support of deterministic communications over standard Ethernet. Several traffic Queues can be defined to support different levels of TSN support (determinism, controlled latency, best efforts, etc.). This software is in charge of setting up the TSN queues and the routing rules so that Traffic with specific QoS requirements can be handled as expected in the TSN network (on-board). This software is required to setup the TSN flows.","title":"TSN Queue Mapper"},{"location":"components/secure_communications/IFAT/","text":"WP3-10 Trusted communication subarchitecture Development of a trusted communication sub-architecture. Shall ensure confidentiality, authenticity and integrity. Focus on the protection of the communication links between drone, remote control and flight control stations. In addition, the protection of the credentials for the authentication of the drone towards the mobile network operator (MNO) for network access is part of this WP.","title":"IFAT - Trusted communication subarchitecture"},{"location":"components/secure_communications/IFAT/#trusted-communication-subarchitecture","text":"Development of a trusted communication sub-architecture. Shall ensure confidentiality, authenticity and integrity. Focus on the protection of the communication links between drone, remote control and flight control stations. In addition, the protection of the credentials for the authentication of the drone towards the mobile network operator (MNO) for network access is part of this WP.","title":"Trusted communication subarchitecture"},{"location":"components/secure_communications/TNL/","text":"WP3-07 Robust Communication Robust communications by means of store- and forwarding methods, using mechanisms from Disruption Tolerant Networking (DTN). Focus is on collection of sensors observations in areas where standard connectivity may be limited. Robust interrupt and tolerant communication system. Study of components, methods algorithms, leading to a small-footprint implementation. Specific focus: quality of service methods (priority classes), routing algorithms (in drone context) (static, epidemic, spray-and-wait) and the possibility to create the functionality in embedded systems with small footprint","title":"TNL - Robust Communication"},{"location":"components/secure_communications/TNL/#robust-communication","text":"Robust communications by means of store- and forwarding methods, using mechanisms from Disruption Tolerant Networking (DTN). Focus is on collection of sensors observations in areas where standard connectivity may be limited. Robust interrupt and tolerant communication system. Study of components, methods algorithms, leading to a small-footprint implementation. Specific focus: quality of service methods (priority classes), routing algorithms (in drone context) (static, epidemic, spray-and-wait) and the possibility to create the functionality in embedded systems with small footprint","title":"Robust Communication"},{"location":"tags.html","text":"Contents grouped by tag a UNISS - Onboard Compute Platform Design Paradigm UNISS - Onboard Compute Platform Design Paradigm a tag EXAMPLE an other tag EXAMPLE architecture EDI SoC Paparazzi BUT algorithms HIB - Computer Vision Components for drones code generation CEA - Reference Architecture Modelling and Code Generation communication CEA - TSN Queue Mapper IFAT - Trusted communication subarchitecture TNL - Robust Communication d UNISS - Onboard Compute Platform Design Paradigm data fusion ACCORDE - Multi-antenna GNSS/INS based navigation MODIS - multi-sensor positioning Detect and Avoid IKERLAN - Safety function - Pre-Certified SOM DJI FADA-CATEC - Indoor positioning module e UNISS - Onboard Compute Platform Design Paradigm energy management UDANET - Smart and predictive energy management system FPGA UNIMORE - Onboard Compute Platform Desing Methodolgy UNIVAQ - Efficient digital implementation of controllers geofencing ENSMA - Control components that implement potential barriers h UNISS - Onboard Compute Platform Design Paradigm hardware EDI SoC TUE - A compact, lightweight platform (MPSOC FPGA-based, incl. RTOS) UNIMORE - Onboard Compute Platform Desing Methodolgy BUT algorithms HIB - Computer Vision Components for drones IMEC - Hyperspectral payload IMEC - Hyperspectral image processing INDRA - Payload (Single Visible HD) ACCORDE - UWB based indoor positioning ACCORDE - Multi-antenna GNSS/INS based navigation MODIS - multi-sensor positioning indoor ACCORDE - UWB based indoor positioning inspection IMEC - Hyperspectral payload IMEC - Hyperspectral image processing LIDAR IKERLAN - Safety function - Pre-Certified SOM FADA-CATEC - Indoor positioning module navigation ENSMA - Control components that implement potential barriers UDANET - Smart and predictive energy management system paparazzi Paparazzi plop UDANET - AI drone system modules UWB - Autonomous drone battery management positioning ACCORDE - UWB based indoor positioning ACCORDE - Multi-antenna GNSS/INS based navigation FADA-CATEC - Indoor positioning module MODIS - multi-sensor positioning r UNISS - Onboard Compute Platform Design Paradigm UNISS - Onboard Compute Platform Design Paradigm ROS FADA-CATEC - Indoor positioning module ROS2 TUE - A compact, lightweight platform (MPSOC FPGA-based, incl. RTOS) SLAM MODIS - multi-sensor positioning SoC EDI SoC BUT algorithms HIB - Computer Vision Components for drones swarm ENSMA - Multi-agent swarm control video processing BUT algorithms HIB - Computer Vision Components for drones IMEC - Hyperspectral payload IMEC - Hyperspectral image processing INDRA - Payload (Single Visible HD) w UNISS - Onboard Compute Platform Design Paradigm","title":"Tags"},{"location":"tags.html#contents-grouped-by-tag","text":"","title":"Contents grouped by tag"},{"location":"tags.html#a","text":"UNISS - Onboard Compute Platform Design Paradigm UNISS - Onboard Compute Platform Design Paradigm","title":"a"},{"location":"tags.html#a-tag","text":"EXAMPLE","title":"a tag"},{"location":"tags.html#an-other-tag","text":"EXAMPLE","title":"an other tag"},{"location":"tags.html#architecture","text":"EDI SoC Paparazzi BUT algorithms HIB - Computer Vision Components for drones","title":"architecture"},{"location":"tags.html#code-generation","text":"CEA - Reference Architecture Modelling and Code Generation","title":"code generation"},{"location":"tags.html#communication","text":"CEA - TSN Queue Mapper IFAT - Trusted communication subarchitecture TNL - Robust Communication","title":"communication"},{"location":"tags.html#d","text":"UNISS - Onboard Compute Platform Design Paradigm","title":"d"},{"location":"tags.html#data-fusion","text":"ACCORDE - Multi-antenna GNSS/INS based navigation MODIS - multi-sensor positioning","title":"data fusion"},{"location":"tags.html#detect-and-avoid","text":"IKERLAN - Safety function - Pre-Certified SOM","title":"Detect and Avoid"},{"location":"tags.html#dji","text":"FADA-CATEC - Indoor positioning module","title":"DJI"},{"location":"tags.html#e","text":"UNISS - Onboard Compute Platform Design Paradigm","title":"e"},{"location":"tags.html#energy-management","text":"UDANET - Smart and predictive energy management system","title":"energy management"},{"location":"tags.html#fpga","text":"UNIMORE - Onboard Compute Platform Desing Methodolgy UNIVAQ - Efficient digital implementation of controllers","title":"FPGA"},{"location":"tags.html#geofencing","text":"ENSMA - Control components that implement potential barriers","title":"geofencing"},{"location":"tags.html#h","text":"UNISS - Onboard Compute Platform Design Paradigm","title":"h"},{"location":"tags.html#hardware","text":"EDI SoC TUE - A compact, lightweight platform (MPSOC FPGA-based, incl. RTOS) UNIMORE - Onboard Compute Platform Desing Methodolgy BUT algorithms HIB - Computer Vision Components for drones IMEC - Hyperspectral payload IMEC - Hyperspectral image processing INDRA - Payload (Single Visible HD) ACCORDE - UWB based indoor positioning ACCORDE - Multi-antenna GNSS/INS based navigation MODIS - multi-sensor positioning","title":"hardware"},{"location":"tags.html#indoor","text":"ACCORDE - UWB based indoor positioning","title":"indoor"},{"location":"tags.html#inspection","text":"IMEC - Hyperspectral payload IMEC - Hyperspectral image processing","title":"inspection"},{"location":"tags.html#lidar","text":"IKERLAN - Safety function - Pre-Certified SOM FADA-CATEC - Indoor positioning module","title":"LIDAR"},{"location":"tags.html#navigation","text":"ENSMA - Control components that implement potential barriers UDANET - Smart and predictive energy management system","title":"navigation"},{"location":"tags.html#paparazzi","text":"Paparazzi","title":"paparazzi"},{"location":"tags.html#plop","text":"UDANET - AI drone system modules UWB - Autonomous drone battery management","title":"plop"},{"location":"tags.html#positioning","text":"ACCORDE - UWB based indoor positioning ACCORDE - Multi-antenna GNSS/INS based navigation FADA-CATEC - Indoor positioning module MODIS - multi-sensor positioning","title":"positioning"},{"location":"tags.html#r","text":"UNISS - Onboard Compute Platform Design Paradigm UNISS - Onboard Compute Platform Design Paradigm","title":"r"},{"location":"tags.html#ros","text":"FADA-CATEC - Indoor positioning module","title":"ROS"},{"location":"tags.html#ros2","text":"TUE - A compact, lightweight platform (MPSOC FPGA-based, incl. RTOS)","title":"ROS2"},{"location":"tags.html#slam","text":"MODIS - multi-sensor positioning","title":"SLAM"},{"location":"tags.html#soc","text":"EDI SoC BUT algorithms HIB - Computer Vision Components for drones","title":"SoC"},{"location":"tags.html#swarm","text":"ENSMA - Multi-agent swarm control","title":"swarm"},{"location":"tags.html#video-processing","text":"BUT algorithms HIB - Computer Vision Components for drones IMEC - Hyperspectral payload IMEC - Hyperspectral image processing INDRA - Payload (Single Visible HD)","title":"video processing"},{"location":"tags.html#w","text":"UNISS - Onboard Compute Platform Design Paradigm","title":"w"}]}